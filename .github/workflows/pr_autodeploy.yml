name: Auto Deploy Databricks Pipeline

on:
  push:
    paths:
      - 'ahd-data-pipelines/conf.j2/**' # Watch for changes in any file under ahd-data-pipelines/conf.j2 directory
  workflow_dispatch: # Allow manual triggering

jobs:
  deploy:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2
      
      - name: Install Databricks CLI
        run: |
          pip install databricks-cli
      
      - name: Set up Databricks CLI
        run: |
          databricks_host="${{ secrets.DATABRICKS_URL_DEV }}"
          if [[ ! $databricks_host =~ ^https:// ]]; then
            databricks_host="https://${databricks_host}"
          fi
          echo -e "${databricks_host}\n${{ secrets.DATABRICKS_TOKEN_DEV }}" | databricks configure --token

      - name: Check Databricks Access
        run: |
          databricks workspace ls

      - name: Get list of changed files
        run: |
          CHANGED_FILES=$(git diff --name-only HEAD^ HEAD)
          echo "Changed files:"
          echo "$CHANGED_FILES" | grep 'ahd-data-pipelines/conf\.j2/'

      - name: Determine changes and deploy pipelines
        run: |
          if echo "$CHANGED_FILES" | grep -q 'ahd-data-pipelines/conf\.j2/parameters/census/language/'; then
            echo "Updating Language Pipeline"
          fi
