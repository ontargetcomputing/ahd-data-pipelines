name: Auto Deploy Databricks Pipeline

on:
  push:
    paths:
      - 'ahd-data-pipelines/conf.j2/**'
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install Poetry
        run: |
          pip install poetry
      
      - name: Install Databricks CLI
        run: |
          /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
          (echo; echo 'eval "$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)"') >> /home/runner/.bashrc
          eval "$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)"
          brew tap databricks/tap
          brew install databricks
          echo fpath+=$(brew --prefix)/share/zsh/site-functions >> ~/.zshrc
          echo 'autoload -Uz compinit && compinit' >> ~/.zshrc
          export PATH="/home/linuxbrew/.linuxbrew/Cellar/databricks/0.219.0/bin:$PATH"
          echo 'export PATH="/home/linuxbrew/.linuxbrew/Cellar/databricks/0.219.0/bin:$PATH"' >> ~/.bashrc
          echo $PATH

      - name: Create Databricks Config File
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_URL_DEV }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN_DEV }}
        run: |
          echo "[DEFAULT]" > ~/.databrickscfg
          echo "host = $DATABRICKS_HOST" >> ~/.databrickscfg
          echo "token = $DATABRICKS_TOKEN" >> ~/.databrickscfg

      - name: Verify successful authentication
        run: /home/linuxbrew/.linuxbrew/Cellar/databricks/0.219.0/bin/databricks clusters list

      - name: Get list of changed files (handle no changes)
        run: |
          CHANGED_FILES=$(git diff --name-only HEAD -- 'ahd-data-pipelines/conf.j2/')
          if [[ -z "$CHANGED_FILES" ]]; then
            echo "No changed files found."
          else
            echo "Changed files:"
            echo "$CHANGED_FILES" | grep 'ahd-data-pipelines/conf\.j2/'
          fi

      - name: Determine changes and deploy pipelines
        run: |
          if echo "$CHANGED_FILES" | grep -q 'ahd-data-pipelines/conf\.j2/parameters/census/language/'; then
            echo "Updating Language Pipeline"
          fi

      - name: Extract census_language section
        run: |
          start_line=$(grep -n 'census_language:' conf.j2/data.ci.yml | cut -d ':' -f 1)
          template_line=$(awk "NR==$start_line+2,/template:/" conf.j2/data.ci.yml | grep -n 'template:' | cut -d ':' -f 1)
          if [ -z "$template_line" ]; then
            end_line=$(wc -l < conf.j2/data.ci.yml)
          else
            end_line=$((start_line + template_line - 2)) # -2 to get the line before 'template:'
          fi
          sed -n "${start_line},${end_line}p" conf.j2/data.ci.yml > census_language_section.yml

      - name: Create new file with census_language section
        run: |
          head -n 3 conf.j2/data.ci.yml > conf.j2/data.ci2.yml
          cat census_language_section.yml >> conf.j2/data.ci2.yml

      - name: Output contents of the new file
        run: cat conf.j2/data.ci2.yml

      - name: Get file path
        run: |
          file_path=$(grep -oP '(?<=template:\s).*' conf.j2/data.ci2.yml | awk '{$1=$1;print}')
          file_path=${file_path//conf/conf.j2}
          grep -A 1 'jobs:' "$file_path"

# [dev richard_bach3] county_language
      - name: Extract template filename and get job name
        id: extract-template
        run: |
          if [ ! -f "conf.j2/data.ci2.yml" ]; then
              echo "Error: conf.j2/data.ci2.yml not found"
              exit 1
          fi

          template_file=$(awk -F 'template: ' 'NF>1{print $2}' conf.j2/data.ci2.yml)
          if [ -z "$template_file" ]; then
              echo "Error: Template filename not found in conf.j2/data.ci2.yml"
              exit 1
          fi

          template_file="${template_file/conf/conf.j2}"

          grep -A 1 'jobs:' "$template_file"

          job_name=$(grep -A 1 'jobs:' "$template_file" | tail -n 1 | sed 's/^[[:space:]]*//;s/[[:space:]]*$//' | sed "s/^[^']*//;s/[^']*\$//")
          if [ -z "$job_name" ]; then
              echo "Error: Job name not found in $template_file"
              exit 1
          fi

          job_name="[dev richard_bach3] ${job_name}"
          echo "::set-output name=job_name::$job_name"

      - name: Use extracted job name
        run: |
          echo "Job Name: ${{ steps.extract-template.outputs.job_name }}"

      - name: Get jobs list
        run: |
          /home/linuxbrew/.linuxbrew/Cellar/databricks/0.219.0/bin/databricks jobs list

# get job id by name
      - name: Get Job ID using Databricks CLI
        id: get-job-id
        run: |
          job_name="county_language"
          job_id=$(databricks jobs list --output JSON | jq -r '.jobs[] | select(.settings.name == "'"${job_name}"'") | .job_id')
          echo "::set-output name=job_id::$job_id"
          echo "Job ID: $job_id"

# start workflow with ID
# check task status


